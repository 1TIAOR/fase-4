# Classifica√ß√£o de Variedades de Gr√£os de Trigo
 ‚Äî CRISP-DM  
Atividade da FASE 04 / CTWP / Cap√≠tulo 3

Este projeto aplica a metodologia **CRISP-DM** para desenvolver um modelo de aprendizado de m√°quina capaz de classificar tr√™s variedades de gr√£os de trigo a partir de suas caracter√≠sticas f√≠sicas.  
O objetivo √© automatizar um processo que, em cooperativas agr√≠colas de pequeno porte, normalmente √© feito manualmente e est√° sujeito a erros humanos.

---

## 1. Dataset Utilizado

O dataset utilizado √© o **Seeds Dataset**, dispon√≠vel no UCI Machine Learning Repository:

üîó https://archive.ics.uci.edu/dataset/236/seeds

Ele cont√©m **210 amostras** distribu√≠das igualmente entre tr√™s variedades de trigo:

- **1 ‚Äî Kama**  
- **2 ‚Äî Rosa**  
- **3 ‚Äî Canadian**

### Atributos:
- area  
- perimeter  
- compactness  
- length_kernel  
- width_kernel  
- asymmetry_coeff  
- length_groove  
- class (vari√°vel alvo)

---

## 2. Metodologia (CRISP-DM)

### **2.1 Business Understanding**
A classifica√ß√£o autom√°tica dos gr√£os ajuda na padroniza√ß√£o e efici√™ncia do processo de sele√ß√£o, reduzindo erros humanos em cooperativas agr√≠colas de pequeno porte.

### 2.2 Data Understanding
Foram realizadas:
- Visualiza√ß√£o das primeiras linhas  
- Estat√≠sticas descritivas  
- Histogramas  
- Boxplots  
- Pairplot (dispers√£o por classe)  
- Matriz de correla√ß√£o  

Principais observa√ß√µes:
- As features **area**, **perimeter**, **length_kernel**, **width_kernel** e **length_groove** t√™m forte correla√ß√£o entre si.  
- N√£o existem valores ausentes.  
- H√° alguns outliers em *compactness* e *asymmetry_coeff*, mas n√£o prejudicam o modelo.

### 2.3 Data Preparation
- Separa√ß√£o dos dados em **70% treino / 30% teste**  
- Padroniza√ß√£o com **StandardScaler**  
- Prepara√ß√£o das features e do target  

---

## 3. Modelagem

Modelos testados:
- KNN  
- SVM  
- Random Forest  
- Naive Bayes  
- Logistic Regression  

M√©tricas utilizadas:
- Acur√°cia  
- Precis√£o  
- Recall  
- F1-score  
- Matriz de confus√£o  

---

## 4. Resultados Obtidos

### Acur√°cia dos modelos

| Modelo | Acur√°cia |
|--------|---------|
| **Random Forest** | **0.9206** |
| KNN | 0.8730 |
| SVM | 0.8730 |
| Logistic Regression | 0.8571 |
| Naive Bayes | 0.8254 |

### Acur√°cia dos modelos otimizados

| Modelo | Tunado | Antes |
|--------|--------|--------|
| **KNN** | **0.9048** | 0.8730 |
| SVM | 0.8571 | 0.8730 |
| Random Forest | 0.8889 | 0.9206 |

###  Observa√ß√µes:
- O **Random Forest** foi o melhor modelo no baseline.  
- O **KNN** foi o que mais melhorou ap√≥s tuning.  
- O SVM n√£o apresentou melhora com tuning nesta base espec√≠fica.  
- As features mais importantes (via RandomForest) foram:  
  1. area  
  2. perimeter  
  3. length_groove  
  4. width_kernel  

---

## 5. Conclus√£o

- O problema √© **vi√°vel** para ser resolvido com machine learning, atingindo mais de **90% de acur√°cia**.  
- O modelo pode auxiliar cooperativas agr√≠colas a classificarem gr√£os com mais padr√£o e menos erro manual.  
- As features relacionadas ao **tamanho do gr√£o** foram as mais relevantes.  
- Modelos simples (como KNN) apresentaram √≥timo desempenho.  
- Random Forest mostrou maior estabilidade e melhor desempenho geral.

### Limita√ß√µes:
- Dataset pequeno (210 amostras).  
- Medidas f√≠sicas podem variar dependendo do m√©todo de coleta.  
- Uma solu√ß√£o real exigiria coleta cont√≠nua e sensores calibrados. 
